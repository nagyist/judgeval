{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the notebook below, we demonstrate how using mixture of agents (MoA) can significantly improve the quality of responses by harnessing the power of multple LLMs. The code below goes in order of using just a single agent/LLM, then using a mixture of agents/LLMs, then using multiple iterations of a mixture of agents/LLMs. The basic architecture we follow is to prompt each LLM, then use an aggregator LLM combined with a final prompt to get the final output.\n",
    "\n",
    "![alt text](8c88157_image.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will build a travel itinerary generator. This emulates the common dilemma of having to figure out flights, hotel, food, attraction planning, etc. delegates these to a mixture of agents to solve. The main request will be split into these subtasks, and a mixture of agents will tackle each task, the results will be aggregated to get refined answers for each task. Then the results of each task will be aggregated to build the final itinerary. Our model will look like this:\n",
    "\n",
    "\n",
    "![alt text](agent_diagram.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build each part of this workflow step by step. At each step, we may decide to incorporate Judgment's scoring and tracing models as well! We will describe how this works in more detail in those cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the necessary packages to leverage Together AI's inference models and mixture of agents framework, as well as Judgments tracing and scoring models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Langfuse client is disabled since no public_key was provided as a parameter or environment variable 'LANGFUSE_PUBLIC_KEY'. See our docs: https://langfuse.com/docs/sdk/python/low-level-sdk#initialize-client\n"
     ]
    }
   ],
   "source": [
    "#general imports\n",
    "import asyncio\n",
    "import os\n",
    "import together\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"pydantic\")\n",
    "\n",
    "#together imports\n",
    "from together import AsyncTogether, Together\n",
    "\n",
    "#judgment imports\n",
    "from judgeval.common.tracer import Tracer, wrap\n",
    "from judgeval.scorers import AnswerRelevancyScorer, SummarizationScorer, FaithfulnessScorer\n",
    "\n",
    "#tavily imports (we use this to help out agent workflow)\n",
    "from tavily import TavilyClient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you have JUDGMENT_API_KEY, TAVILY_API_KEY, TOGETHER_API_KEY set in your environment variables. In order to obtain a JUDGMENT_API_KEY please email us at contact@judgmentlabs.ai. You can obtain a TAVILY_API_KEY through the Getting Started Guide on Tavily's website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the clients we use for inference and also Judgment's tracers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initialized JudgmentClient, welcome back user!\n"
     ]
    }
   ],
   "source": [
    "client = wrap(Together(api_key=os.environ.get(\"TOGETHER_API_KEY\")))\n",
    "async_client = AsyncTogether(api_key=os.environ.get(\"TOGETHER_API_KEY\"))\n",
    "judgment = Tracer(project_name=\"travel_agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Breakdown Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to **break down the user's prompt** into subtasks. For this, we can leverage one LLM to break it down into the task descriptions we want.\n",
    "\n",
    "Say our user's prompt is \"Make me an itinerary to Spain for one week from Feb 20 to March 1\", then we want to break this large problem down into subproblems. Making an itinerary involves a lot of things: finding accommodations, finding activities, making a list of all the things to see, trying new restuarants, etc. We will invoke an LLM call to help us break our request into specific subproblems and tasks that we will later use MOA to solve. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets come up with system and user prompts for this LLM to complete the breakdown of tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"Make me an itinerary to Spain for one week from Feb 20 to March 1\"\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "    You are an AI assistant that breaks down a user's request about making a travel itinerary for their upcoming trip into \n",
    "    specific subtasks. You will need to break down the user's request into a task description and then create a clear, \n",
    "    detailed prompt addressing that task. Each prompt should be self-contained with all necessary information from the \n",
    "    original request. Do not add any explanations or commentary - only output the JSON object. You should output a JSON \n",
    "    object where the key is the task description and the value is the specialized prompt you came up with to solve the task.\n",
    "    As an example output, you could return the following key-value pair for a specific task :\n",
    "    {\n",
    "        \"Find flights and hotels for the trip\": \"Search for flights from the user's preferred airport to Spain from February 20 to March 1 and find available hotels in the desired location for the entire \n",
    "        duration of the trip, considering factors such as budget, location, and user reviews\"\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "user_message = f\"\"\"\n",
    "    Original user request: \"{user_prompt}\"\n",
    "\n",
    "    Break this down into separate prompts for specialized agents to handle each subtask.\n",
    "\n",
    "    Return the result as a JSON string where the keys are the task descriptions that I provided \n",
    "    and the values are the specialized and more refined prompts that you came up with to solve the task. \n",
    "    Dont include any ```json tags, just return the JSON that has simple key-value pairs.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's write the function that will actually call the LLM using the prompts from above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Determine travel dates and duration\": \"Identify the start and end dates of the trip as February 20 to March 1 and calculate the duration as one week\",\n",
      "    \"Find flights to Spain\": \"Search for flights from the user's preferred airport to Spain from February 20 to March 1, considering factors such as budget, flight duration, and layovers\",\n",
      "    \"Book accommodations in Spain\": \"Find available hotels in Spain for the entire duration of the trip from February 20 to March 1, considering factors such as budget, location, and user reviews\",\n",
      "    \"Research popular destinations and activities in Spain\": \"Identify top tourist attractions, cultural events, and experiences in Spain that the user may be interested in, such as visiting Madrid, Barcelona, or Seville\",\n",
      "    \"Create a daily schedule for the trip\": \"Plan a daily itinerary for the user's trip to Spain, including transportation, meals, and activities, from February 20 to March 1\",\n",
      "    \"Provide transportation options within Spain\": \"Research and recommend transportation options within Spain, such as trains, buses, or car rentals, for the user to travel between destinations\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo\", \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_message}\n",
    "    ],\n",
    "    stream=False,\n",
    ")\n",
    "# Get the response content which should include the task breakdown\n",
    "print(json.dumps(json.loads(response.choices[0].message.content), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now before we call this function, let's think about how we can evaluate its effectiveness using Judgment. We want a way to assess how well the language model breaks down the original request into different subtasks, as we instructed it to do.\n",
    "\n",
    "This is a perfect opportunity to apply the ```AnswerRelevancyScorer``` from Judgment. This scorer helps us determine whether our individual steps succeeded in addressing the user's request. For example, when breaking down tasks, we want to ensure that our subtask for finding hotels searches for the correct date range, or that our transportation plan correctly references the areas we're traveling to. \n",
    "\n",
    "As per the docs:\n",
    "> \"AnswerRelevancy scores are calculated by extracting statements made in the actual_output and \n",
    "> classifying how many are relevant to the input.\n",
    "> \n",
    "> The score is calculated as:\n",
    "> relevancy score = relevant statements / total statements\"\n",
    "\n",
    "By setting a threshold (e.g., 0.8), we can determine whether each part of our solution is sufficiently \n",
    "aligned with the user's request. This helps us catch issues such as:\n",
    "- The ‚ÄúFind Hotels‚Äù subtask returning results outside the intended date range.\n",
    "- The ‚ÄúPlan Transportation‚Äù subtask referencing the wrong location.\n",
    "\n",
    "The ```AnswerRelevancyScorer``` flags parts of the output that aren‚Äôt relevant to the user‚Äôs needs, helping us \n",
    "quantitatively evaluate how well each subtask performs.  You can read more about Judgment's suite of scoring models here: https://judgment.mintlify.app/introduction\n",
    "\n",
    "```scorer = AnswerRelevancyScorer(threshold=0.8)\n",
    "results = client.run_evaluation(\n",
    "    examples=[example],\n",
    "    scorers=[scorer],\n",
    "    model=\"gpt-4o\",\n",
    ")```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This also seems like a perfect place to also add Judgment's Tracing! After we provide the LLM with the input and system prompts, it will produce an output. Since we are scoring our output, it would be nice to see what inputs are associated with that score and output, thats where we use tracing! We can simply add a decorator on our functions like:\n",
    "\n",
    "`@judgment.observe(span_type=\"tool\", overwrite=True)`\n",
    "\n",
    "And it will start to trace the inputs and outputs everytime we call that model. Lets put this all together now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "üîç You can view your trace data here: \n",
       "<span style=\"color: #6a00ff; text-decoration-color: #6a00ff; text-decoration: underline\">https://app.judgmentlabs.ai/app/trace?trace_id=6ff4ec8f-7939-4501-aaae-7789e15ddd40</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "üîç You can view your trace data here: \n",
       "\u001b[4;38;2;106;0;255mhttps://app.judgmentlabs.ai/app/trace?\u001b[0m\u001b[4;38;2;106;0;255mtrace_id\u001b[0m\u001b[4;38;2;106;0;255m=\u001b[0m\u001b[4;38;2;106;0;255m6ff4ec8f\u001b[0m\u001b[4;38;2;106;0;255m-7939-4501-aaae-7789e15ddd40\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Determine travel dates and duration\": \"Confirm the travel dates as February 20 to March 1 and calculate the duration as one week\",\n",
      "    \"Find flights and hotels for the trip\": \"Search for flights from the user's preferred airport to Spain from February 20 to March 1 and find available hotels in the desired location for the entire duration of the trip, considering factors such as budget, location, and user reviews\",\n",
      "    \"Plan daily activities and sightseeing\": \"Research and suggest popular tourist attractions, cultural events, and activities in Spain for each day of the trip from February 20 to March 1, taking into account the user's interests and preferences\",\n",
      "    \"Create a transportation plan\": \"Develop a plan for transportation within Spain, including options for getting from the airport to the hotel, traveling between cities, and getting around local areas, considering factors such as cost, convenience, and time efficiency\",\n",
      "    \"Research and book restaurants and local experiences\": \"Find and recommend local restaurants, bars, and experiences in Spain, such as flamenco shows, wine tastings, or cooking classes, and provide information on how to book or reserve them in advance\",\n",
      "    \"Prepare a budget and financial plan\": \"Estimate the total cost of the trip, including flights, hotels, food, transportation, and activities, and provide guidance on how to manage expenses, exchange currency, and make payments while in Spain\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "@judgment.observe(span_type=\"tool\", overwrite=True)\n",
    "def main():\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo\", \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_message}\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    judgment.get_current_trace().async_evaluate(\n",
    "        scorers=[AnswerRelevancyScorer(threshold=0.5)],\n",
    "        input=user_message,\n",
    "        actual_output=response.choices[0].message.content,\n",
    "        model=\"gpt-4\",\n",
    "    )\n",
    "    \n",
    "    return json.loads(response.choices[0].message.content)\n",
    "\n",
    "task_breakdown = main()\n",
    "print(json.dumps(task_breakdown, indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MoA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This helper function will help us search real information related to our tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tavily(query):\n",
    "    \"\"\"Fetch travel data using Tavily API.\"\"\"\n",
    "    API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "    client = TavilyClient(api_key=API_KEY)\n",
    "    results = client.search(query, num_results=3)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is where we implement MOA. This is the middle portion of our diagram from the beginning. For each task, we will have multiple agents/LLMs work on it, then we will take the results of each LLM and aggregate them to curate our final response. Heres what those models and prompts look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_models = [\n",
    "    \"Qwen/Qwen2-72B-Instruct\",\n",
    "    \"meta-llama/Llama-3.3-70B-Instruct-Turbo\",\n",
    "    \"mistralai/Mixtral-8x22B-Instruct-v0.1\",\n",
    "    \"databricks/dbrx-instruct\",\n",
    "]\n",
    "\n",
    "aggregator_model = \"mistralai/Mixtral-8x22B-Instruct-v0.1\"\n",
    "aggreagator_system_prompt = \"\"\"\n",
    "    You have been provided with a set of responses from various open-source models to the latest user query. \n",
    "    Your task is to synthesize these responses into a single, high-quality response. It is crucial to critically \n",
    "    evaluate the information provided in these responses, recognizing that some of it may be biased or incorrect. \n",
    "    Your response should not simply replicate the given answers but should offer a refined, accurate, and comprehensive \n",
    "    reply to the instruction. Ensure your response is well-structured, coherent, and adheres to the highest standards of \n",
    "    accuracy and reliability.\n",
    "\n",
    "    Responses from models:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets modularize our code so that we can easily make a call to one of our reference models. We will use Together's AsyncClient so that we can asynchornously launch each agent with the prompt and then wait for them to all come back with a response. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_llm(model, task_prompt, context):\n",
    "    \"\"\"Run a single LLM call with a reference model.\"\"\"\n",
    "    response = await async_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": f\"{task_prompt}. Here is some additional context to help you: {context}\"}],\n",
    "        temperature=0.7,\n",
    "        max_tokens=512,\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's write the function that will aggregate all the responses from our agents. This is another critical moment for evaluation - we need to assess how effectively we combine the research from individual agents into a cohesive itinerary.\n",
    "\n",
    "For this aggregation phase, we'll again use Judgment's `AnswerRelevancyScorer` to evaluate how well our final itinerary addresses the original user request. This time, we're checking if our combined output - drawing from hotel research, transportation plans, activity suggestions, and restaurant recommendations - effectively delivers a complete travel plan that meets all aspects of the user's query. For instance, finding hotels could mistsakenly return options outside the requested date range, or the transportation plan could incorrectly reference the wrong destination.\n",
    "\n",
    "By tracing these outputs through Judgment, we can identify any potential disconnects between the research phase and the final aggregation, ensuring our multi-agent orchestration delivers truly helpful travel plans.\n",
    "\n",
    "```scorer = AnswerRelevancyScorer(threshold=0.8)\n",
    "results = client.run_evaluation(\n",
    "    examples=[example],\n",
    "    scorers=[scorer],\n",
    "    model=\"gpt-4o\",\n",
    ")```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@judgment.observe(span_type=\"tool\", overwrite=True)\n",
    "async def run_aggregator(task_prompt, context):\n",
    "    results = await asyncio.gather(*[run_llm(model, task_prompt, context) for model in reference_models])\n",
    "\n",
    "    finalStream = client.chat.completions.create(\n",
    "        model=aggregator_model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": aggreagator_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": \",\".join(str(element) for element in results)},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    judgment.get_current_trace().async_evaluate(\n",
    "        scorers=[AnswerRelevancyScorer(threshold=0.5)],\n",
    "        input=task_prompt,\n",
    "        actual_output=finalStream.choices[0].message.content,\n",
    "        model=\"gpt-4\",\n",
    "    )\n",
    "    return finalStream.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets start using the functions we wrote above to launch a MoA for each one of our tasks. We will get a trace URL for each task so we can evaluate each of them seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on task: Determine travel dates and duration\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "üîç You can view your trace data here: \n",
       "<span style=\"color: #6a00ff; text-decoration-color: #6a00ff; text-decoration: underline\">https://app.judgmentlabs.ai/app/trace?trace_id=e5209a27-76c5-48ac-8653-e375d1fdc248</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "üîç You can view your trace data here: \n",
       "\u001b[4;38;2;106;0;255mhttps://app.judgmentlabs.ai/app/trace?\u001b[0m\u001b[4;38;2;106;0;255mtrace_id\u001b[0m\u001b[4;38;2;106;0;255m=\u001b[0m\u001b[4;38;2;106;0;255me5209a27\u001b[0m\u001b[4;38;2;106;0;255m-76c5-48ac-8653-e375d1fdc248\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on task: Find flights and hotels for the trip\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "üîç You can view your trace data here: \n",
       "<span style=\"color: #6a00ff; text-decoration-color: #6a00ff; text-decoration: underline\">https://app.judgmentlabs.ai/app/trace?trace_id=aa45bee5-106a-4b30-9ad7-80a8ded686e9</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "üîç You can view your trace data here: \n",
       "\u001b[4;38;2;106;0;255mhttps://app.judgmentlabs.ai/app/trace?\u001b[0m\u001b[4;38;2;106;0;255mtrace_id\u001b[0m\u001b[4;38;2;106;0;255m=\u001b[0m\u001b[4;38;2;106;0;255maa45bee5\u001b[0m\u001b[4;38;2;106;0;255m-106a-4b30-9ad7-80a8ded686e9\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on task: Plan daily activities and sightseeing\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "üîç You can view your trace data here: \n",
       "<span style=\"color: #6a00ff; text-decoration-color: #6a00ff; text-decoration: underline\">https://app.judgmentlabs.ai/app/trace?trace_id=08dfa156-0505-4971-b885-85654402101c</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "üîç You can view your trace data here: \n",
       "\u001b[4;38;2;106;0;255mhttps://app.judgmentlabs.ai/app/trace?\u001b[0m\u001b[4;38;2;106;0;255mtrace_id\u001b[0m\u001b[4;38;2;106;0;255m=\u001b[0m\u001b[4;38;2;106;0;255m08dfa156\u001b[0m\u001b[4;38;2;106;0;255m-0505-4971-b885-85654402101c\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on task: Create a transportation plan\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "üîç You can view your trace data here: \n",
       "<span style=\"color: #6a00ff; text-decoration-color: #6a00ff; text-decoration: underline\">https://app.judgmentlabs.ai/app/trace?trace_id=2b986d1e-c0be-4366-ae51-40609c0accef</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "üîç You can view your trace data here: \n",
       "\u001b[4;38;2;106;0;255mhttps://app.judgmentlabs.ai/app/trace?\u001b[0m\u001b[4;38;2;106;0;255mtrace_id\u001b[0m\u001b[4;38;2;106;0;255m=\u001b[0m\u001b[4;38;2;106;0;255m2b986d1e\u001b[0m\u001b[4;38;2;106;0;255m-c0be-4366-ae51-40609c0accef\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on task: Research and book restaurants and local experiences\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "üîç You can view your trace data here: \n",
       "<span style=\"color: #6a00ff; text-decoration-color: #6a00ff; text-decoration: underline\">https://app.judgmentlabs.ai/app/trace?trace_id=37270174-6a06-4548-9079-aba86cb30892</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "üîç You can view your trace data here: \n",
       "\u001b[4;38;2;106;0;255mhttps://app.judgmentlabs.ai/app/trace?\u001b[0m\u001b[4;38;2;106;0;255mtrace_id\u001b[0m\u001b[4;38;2;106;0;255m=\u001b[0m\u001b[4;38;2;106;0;255m37270174\u001b[0m\u001b[4;38;2;106;0;255m-6a06-4548-9079-aba86cb30892\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on task: Prepare a budget and financial plan\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "üîç You can view your trace data here: \n",
       "<span style=\"color: #6a00ff; text-decoration-color: #6a00ff; text-decoration: underline\">https://app.judgmentlabs.ai/app/trace?trace_id=5e582eb3-ed81-41f1-b3b8-ff5f5ac3ae27</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "üîç You can view your trace data here: \n",
       "\u001b[4;38;2;106;0;255mhttps://app.judgmentlabs.ai/app/trace?\u001b[0m\u001b[4;38;2;106;0;255mtrace_id\u001b[0m\u001b[4;38;2;106;0;255m=\u001b[0m\u001b[4;38;2;106;0;255m5e582eb3\u001b[0m\u001b[4;38;2;106;0;255m-ed81-41f1-b3b8-ff5f5ac3ae27\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "task_outputs = {}\n",
    "for task in task_breakdown:\n",
    "    print(f\"Working on task: {task}\")\n",
    "    task_prompt = task_breakdown[task]\n",
    "    \n",
    "    # Fetch some additional context using Tavily\n",
    "    context = search_tavily(task_prompt)\n",
    "    \n",
    "    taskOutput = await run_aggregator(task_prompt, context)\n",
    "    task_outputs[task] = taskOutput\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Itinerary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we put things together to build the final complete itinerary! We take the aggregated results from the MoA for each task and then pass it back to one model to curate an itinerary based on all the real information we collected. This is the right most part of our initial diagram. Again, we can apply Judgments tracing and scoring tools to see how faithful our final answer to the very first user's prompt! This time we use a different scoring metric, FaithfullnessScorer.\n",
    "\n",
    "Lets come up with our prompts first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "    You are an expert travel planner who creates cohesive, well-structured itineraries.\n",
    "    Your task is to create a final, comprehensive response that combines specialized information\n",
    "    from different agents into a single, flowing itinerary that addresses the user's original request.\n",
    "\n",
    "    The final response should:\n",
    "    1. Start with a brief introduction to the trip\n",
    "    2. Organize information in a logical, chronological structure (day by day)\n",
    "    3. Seamlessly integrate travel logistics, accommodations, meals, and activities\n",
    "    4. Ensure there are no scheduling conflicts or logistical impossibilities\n",
    "    5. Add transitions between sections to create a natural flow\n",
    "    6. End with a brief conclusion\n",
    "\n",
    "    Format the itinerary professionally, with clear headings, and make it easy to follow.\n",
    "\"\"\"\n",
    "\n",
    "user_message = f\"\"\"\n",
    "    Original user request: \"{user_prompt}\"\n",
    "\n",
    "    Specialized agent responses:\n",
    "\n",
    "    {json.dumps(task_outputs, indent=2)}\n",
    "\n",
    "    Please create a cohesive, well-structured final response that combines all this information\n",
    "    into a comprehensive itinerary. Organize it in a logical way (day by day) and ensure the whole\n",
    "    itinerary flows naturally and makes logistical sense.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets make one final LLM call to put together all our results we got from our fleet of agents!\n",
    "\n",
    "This is the perfect place to introduce Judgment's `FaithfulnessScorer`. This scoring model will help us verify that our final itinerary accurately reflects all the information gathered during our research phase. When building a complex itinerary, it's critical that we don't misinterpret which restaurants we'll visit on specific days, mix up attraction details, or create logistical impossibilities.\n",
    "\n",
    "By using the `FaithfulnessScorer`, we'll measure how accurately our final itinerary incorporates the specialized information collected by our agents. The `actual_output` parameter will represent our compiled itinerary, while the `retrieval_context` parameter will contain all the researched information our agents collected - ensuring we create a travel plan that's not just coherent, but factually accurate according to our research. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "üîç You can view your trace data here: \n",
       "<span style=\"color: #6a00ff; text-decoration-color: #6a00ff; text-decoration: underline\">https://app.judgmentlabs.ai/app/trace?trace_id=215710b1-de73-4633-bc8f-99f18c7e8a27</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "üîç You can view your trace data here: \n",
       "\u001b[4;38;2;106;0;255mhttps://app.judgmentlabs.ai/app/trace?\u001b[0m\u001b[4;38;2;106;0;255mtrace_id\u001b[0m\u001b[4;38;2;106;0;255m=\u001b[0m\u001b[4;38;2;106;0;255m215710b1\u001b[0m\u001b[4;38;2;106;0;255m-de73-4633-bc8f-99f18c7e8a27\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Introduction to Your Spanish Adventure**\n",
      "From February 20 to March 1, 2025, you'll embark on a 9-day journey through Spain, exploring its vibrant cities, rich culture, and breathtaking landscapes. This itinerary combines the best of travel logistics, accommodations, meals, and activities to ensure a memorable experience.\n",
      "\n",
      "### Day 1: February 20 - Arrival in Madrid\n",
      "- **Morning:** Arrive at Adolfo Su√°rez Madrid‚ÄìBarajas Airport (MAD). Use a private transfer service like Viator or GetTransfer for a convenient and stress-free journey to your hotel.\n",
      "- **Afternoon:** Check-in at your hotel and explore the nearby area. Consider staying in the city center for easy access to major attractions.\n",
      "- **Evening:** Visit the Retiro Park, one of Madrid's most beautiful green spaces, and enjoy a tapas tour in the city center to get a taste of local cuisine.\n",
      "\n",
      "### Day 2: February 21 - Madrid\n",
      "- **Morning:** Ski at Puerto de Navacerrada, enjoying the views of Sierra de Guadarrama. Rent equipment and book lessons if needed.\n",
      "- **Afternoon:** Visit the historic center of Madrid, including the Plaza Mayor and Palacio Real. Explore the Prado Museum, famous for its extensive collection of European art.\n",
      "- **Evening:** Attend a flamenco show, a quintessential Spanish experience.\n",
      "\n",
      "### Day 3: February 22 - Travel to Cadiz\n",
      "- **Day:** Travel to Cadiz by high-speed train. Book your tickets in advance through Renfe for the best rates.\n",
      "- **Evening:** Relax and explore Cadiz's old town. Enjoy local seafood and wine at one of the traditional restaurants.\n",
      "\n",
      "### Day 4: February 23 - Cadiz\n",
      "- **Day:** Attend the vibrant Cadiz Carnival, famous for its parades and costumes. Be sure to book your accommodations and carnival tickets well in advance.\n",
      "- **Evening:** Experience the local nightlife, visiting bars and clubs in the old town.\n",
      "\n",
      "### Day 5: February 24 - Travel to Seville\n",
      "- **Day:** Travel to Seville by train. Visit the Alc√°zar of Seville and the Cathedral in the afternoon.\n",
      "- **Evening:** Enjoy a traditional Spanish dinner at a local restaurant. Try local specialties like tapas and gazpacho.\n",
      "\n",
      "### Day 6: February 25 - Seville\n",
      "- **Day:** Explore the city's museums and art galleries. Consider purchasing a museum pass for discounted entry to multiple attractions.\n",
      "- **Evening:** Take a walking tour of Seville's historic neighborhoods, including the Santa Cruz quarter.\n",
      "\n",
      "### Day 7: February 26 - Travel to Granada\n",
      "- **Day:** Travel to Granada by train. Visit the Alhambra, a stunning Moorish palace, in the afternoon. Book your Alhambra tickets in advance to avoid sold-out situations.\n",
      "- **Evening:** Relax at a local cafe and enjoy the views of the Albaic√≠n neighborhood.\n",
      "\n",
      "### Day 8: February 27 - Granada\n",
      "- **Day:** Ski in the Sierra Nevada mountains. Rent equipment and book guided tours if necessary.\n",
      "- **Evening:** Experience the local gastronomy, trying traditional dishes like paella and tortilla.\n",
      "\n",
      "### Day 9: February 28 - Travel to Barcelona, March 1 - Barcelona\n",
      "- **Day 28:** Travel to Barcelona by train. Explore the Gothic Quarter in the evening.\n",
      "- **March 1:** \n",
      "  - **Morning:** Visit Antoni Gaudi's architectural marvels, including the Sagrada Familia. Book your tickets in advance.\n",
      "  - **Afternoon:** Relax at the beach or explore the Park G√ºell.\n",
      "  - **Evening:** Enjoy a farewell dinner at a local restaurant, trying Catalan cuisine.\n",
      "\n",
      "### Budget and Financial Plan\n",
      "- **Estimated Total Cost:** $3,800 to $13,261 for two people, depending on your travel style and preferences.\n",
      "- **Breakdown:**\n",
      "  - Flights: $700 per person (average)\n",
      "  - Accommodation: $100 per night (budget) to $209 per night (high-end)\n",
      "  - Food, Drink & Activities: $100 per day for two people\n",
      "  - Transportation: $300 for the week\n",
      "  - Other Expenses: Variable\n",
      "- **Tips:**\n",
      "  - Set a budget and research costs in advance.\n",
      "  - Use discount services for flights, hotels, and activities.\n",
      "  - Consider travel insurance and local transport passes.\n",
      "\n",
      "### Conclusion\n",
      "Your 9-day Spanish adventure is packed with cultural experiences, outdoor activities, and sightseeing. From the vibrant cities of Madrid and Barcelona to the historic charm of Seville and Granada, and the festive atmosphere of Cadiz, this itinerary offers a comprehensive taste of Spain. Remember to book your flights, hotels, and activities in advance to ensure availability and the best rates. With careful planning and an open mind, you're ready to embark on an unforgettable journey through one of Europe's most captivating countries. ¬°Disfruta tu viaje a Espa√±a! (Enjoy your trip to Spain!)\n"
     ]
    }
   ],
   "source": [
    "@judgment.observe(span_type=\"tool\", overwrite=True)\n",
    "def compile_final_itinerary():\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_message}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    judgment.get_current_trace().async_evaluate(\n",
    "        scorers=[FaithfulnessScorer(threshold=0.5)],\n",
    "        input=user_prompt,\n",
    "        actual_output=response.choices[0].message.content,\n",
    "        retrieval_context=task_outputs.values(),\n",
    "        model=\"gpt-4\",\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "final_itinerary = compile_final_itinerary()\n",
    "print(final_itinerary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there we go, we built together a fully-functioning travel itinerary creator by leveraging a mixture of agents to solve each task and we also evaluated the outputs from every step using Judgment's tracing and scoring models!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nbalive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
